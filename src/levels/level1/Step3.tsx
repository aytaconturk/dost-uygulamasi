import { useEffect, useMemo, useRef, useState } from 'react';
import axios from 'axios';
import { getApiBase, getApiEnv } from '../../lib/api';
import { getUser } from '../../lib/user';
import VoiceRecorder from '../../components/VoiceRecorder';
import { submitChildrenVoice, type Level1ChildrenVoiceResponse } from '../../lib/level1-api';
import {
  getParagraphs,
  paragraphToPlain,
  getFirstThreeParagraphFirstSentences,
  getFirstSentence,
  type Paragraph,
} from '../../data/stories';
import { useStepContext } from '../../contexts/StepContext';
import { getStoryById } from '../../lib/supabase';
import { getStoryImageUrl } from '../../lib/image-utils';
import { useAudioPlaybackRate } from '../../hooks/useAudioPlaybackRate';
import { getPlaybackRate } from '../../components/SidebarSettings';

export default function Step3() {
  const [story, setStory] = useState<{ id: number; title: string; image: string } | null>(null);
  const { sessionId, storyId } = useStepContext();
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const hasStartedRef = useRef(false); // Sadece bir kez ba≈ülatmak i√ßin flag
  
  // Apply playback rate to audio element
  useAudioPlaybackRate(audioRef);

  // Load story data from Supabase
  useEffect(() => {
    const loadStory = async () => {
      try {
        const { data, error } = await getStoryById(storyId);
        if (error || !data) {
          // Fallback to default story - use local image path
          setStory({
            id: storyId,
            title: `Oturum ${storyId}`,
            image: `/images/story${storyId}.png`,
          });
        } else {
          // Use image from Supabase if available, otherwise use local path
          const imagePath = data.image || `/images/story${storyId}.png`;
          setStory({
            id: data.id,
            title: data.title,
            image: imagePath,
          });
        }
      } catch (e) {
        // Fallback to default story - use local image path
        setStory({
          id: storyId,
          title: `Oturum ${storyId}`,
          image: `/images/story${storyId}.png`,
        });
      }
    };
    loadStory();
  }, [storyId]);

  const [phase, setPhase] = useState<'intro' | 'dost' | 'student'>( 'intro' );
  const [analysisText, setAnalysisText] = useState<string>('');
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [childrenVoiceResponse, setChildrenVoiceResponse] = useState<string>('');
  const [isProcessingVoice, setIsProcessingVoice] = useState(false);
  const [firstSentences, setFirstSentences] = useState<string[]>([]);
  const [resumeUrl, setResumeUrl] = useState<string>('');

  const stepAudio = '/audios/level1/seviye-1-adim-3-fable.mp3';

  const paragraphs = useMemo(() => story ? getParagraphs(story.id) : [], [story?.id]);

  useEffect(() => {
    if (story) {
      getFirstThreeParagraphFirstSentences(story.id).then((sentences) => {
        console.log('üìù getFirstThreeParagraphFirstSentences sonucu:', sentences);
        setFirstSentences(sentences);
      });
    }
  }, [story?.id]);

  // helpers to compute first sentence length per paragraph
  const firstSentenceLengths = useMemo(() => {
    return paragraphs.map((p, idx) => {
      const plain = paragraphToPlain(p);
      if (idx < 3) {
        const fs = firstSentences[idx] || '';
        return fs.length;
      }
      // compute generically
      const match = plain.match(/[^.!?\n]+[.!?]?/);
      return match ? match[0].trim().length : 0;
    });
  }, [paragraphs, firstSentences]);

  useEffect(() => {
    console.log('üîÑ Step3 useEffect √ßalƒ±≈ütƒ±:', { 
      hasStarted: hasStartedRef.current, 
      hasStory: !!story, 
      firstSentencesLength: firstSentences.length 
    });
    
    // Eƒüer zaten ba≈ülatƒ±lmƒ±≈üsa, tekrar √ßalƒ±≈ütƒ±rma
    if (hasStartedRef.current) {
      console.log('‚è≠Ô∏è Zaten ba≈ülatƒ±lmƒ±≈ü, atlanƒ±yor');
      return;
    }
    
    // Story ve firstSentences y√ºklenene kadar bekle
    if (!story || firstSentences.length === 0) {
      console.log('‚è≥ Bekleniyor... story:', !!story, 'firstSentences:', firstSentences.length);
      return;
    }
    
    // Flag'i i≈üaretle - artƒ±k tekrar √ßalƒ±≈ümayacak
    hasStartedRef.current = true;
    console.log('‚úÖ Step3 ba≈ülatƒ±lƒ±yor!', { 
      story: story.title, 
      firstSentencesCount: firstSentences.length,
      firstSentences: firstSentences
    });
    
    const startDostFlow = () => {
      console.log('üé¨ DOST analysis ba≈ülƒ±yor...');
      setPhase('dost');
      runDostAnalysis();
    };
    
    // Audio element'in mount olmasƒ± i√ßin kƒ±sa bir gecikme
    console.log('‚è±Ô∏è setTimeout ba≈ülatƒ±lƒ±yor (200ms)...');
    const timeoutId = setTimeout(() => {
      console.log('‚è±Ô∏è setTimeout tamamlandƒ±, audio kontrol ediliyor...');
      const el = audioRef.current;
      console.log('üîç audioRef.current:', el ? 'VAR' : 'YOK');
      
      if (el) {
        console.log('üéµ Step3 intro audio y√ºkleniyor:', stepAudio);
        el.src = stepAudio;
        // @ts-ignore
        el.playsInline = true;
        el.muted = false;
        el.playbackRate = getPlaybackRate();
        
        const handleCanPlay = () => {
          console.log('‚úÖ Step3 audio hazƒ±r, oynatƒ±lƒ±yor...');
          el.play()
            .then(() => {
              console.log('‚úÖ Step3 audio oynatƒ±lƒ±yor');
              el.addEventListener('ended', () => {
                console.log('‚úÖ Step3 audio bitti, DOST analysis ba≈ülƒ±yor');
                startDostFlow();
              }, { once: true });
            })
            .catch((err) => {
              console.warn('‚ö†Ô∏è Step3 audio oynatƒ±lamadƒ±:', err);
              startDostFlow();
            });
        };
        
        const handleError = (e: Event) => {
          console.error('‚ùå Step3 audio y√ºklenemedi:', e);
          startDostFlow();
        };
        
        el.addEventListener('canplay', handleCanPlay, { once: true });
        el.addEventListener('error', handleError, { once: true });
        
        // If already loaded, play immediately
        if (el.readyState >= 2) {
          console.log('‚úÖ Step3 audio zaten y√ºkl√º');
          handleCanPlay();
        } else {
          el.load();
        }
      } else {
        console.log('‚ö†Ô∏è Audio element bulunamadƒ±, direkt DOST analysis ba≈ülƒ±yor');
        startDostFlow();
      }
    }, 200); // 100ms'den 200ms'e √ßƒ±karƒ±ldƒ±
    
    const stopAll = () => {
      if (audioRef.current) {
        try { audioRef.current.pause(); } catch {}
      }
    };
    window.addEventListener('STOP_ALL_AUDIO' as any, stopAll);
    
    return () => {
      // Eƒüer ba≈ülatƒ±lmƒ±≈üsa cleanup yapma (timeout iptal etme)
      if (hasStartedRef.current) {
        console.log('üõë Cleanup atlandƒ± (zaten ba≈ülatƒ±lmƒ±≈ü)');
        window.removeEventListener('STOP_ALL_AUDIO' as any, stopAll);
        return;
      }
      
      console.log('üßπ Cleanup yapƒ±lƒ±yor (hen√ºz ba≈ülatƒ±lmamƒ±≈ü)');
      clearTimeout(timeoutId);
      window.removeEventListener('STOP_ALL_AUDIO' as any, stopAll);
      if (audioRef.current) {
        try { audioRef.current.pause(); audioRef.current.currentTime = 0; } catch {}
      }
    };
  }, [story, firstSentences]); // Dependency array eklendi!

  // Text-to-speech removed - only use mp3 files or API base64 audio

  const playAudioFromBase64 = async (base64: string) => {
    if (!audioRef.current || !base64) throw new Error('no audio');
    const tryMime = async (mime: string) => {
      const src = base64.trim().startsWith('data:') ? base64.trim() : `data:${mime};base64,${base64.trim()}`;
      audioRef.current!.src = src;
      await audioRef.current!.play();
      await new Promise<void>((resolve) => {
        audioRef.current!.addEventListener('ended', () => resolve(), { once: true });
      });
    };
    try {
      await tryMime('audio/mpeg');
    } catch {
      try { await tryMime('audio/webm;codecs=opus'); } catch { await tryMime('audio/wav'); }
    }
  };

  const runDostAnalysis = async () => {
    if (!story) return;
    
    // firstSentences y√ºklenmemi≈üse bekle
    if (firstSentences.length === 0) {
      console.log('‚è≥ firstSentences hen√ºz hazƒ±r deƒüil, bekleniyor...');
      return;
    }
    
    // Eƒüer zaten analiz edilmi≈üse tekrar √ßalƒ±≈ütƒ±rma
    if (analysisText) {
      console.log('‚è≠Ô∏è Analysis zaten yapƒ±lmƒ±≈ü, atlanƒ±yor');
      return;
    }
    
    setIsAnalyzing(true);
    console.log('üîç DOST analysis API √ßaƒürƒ±sƒ± yapƒ±lƒ±yor...', {
      story: story.title,
      firstSentencesCount: firstSentences.length,
      firstSentences: firstSentences
    });
    
    try {
      const u = getUser();
      // ‚ö†Ô∏è n8n workflow "userId" alanƒ±nƒ± bekliyor
      // Deƒüer olarak sessionId g√∂nderiliyor (her session i√ßin unique)
      // Bu sayede aynƒ± kullanƒ±cƒ±nƒ±n farklƒ± hikayeleri karƒ±≈ümaz
      const { data } = await axios.post(
        `${getApiBase()}/dost/level1/step3`,
        { title: story.title, firstSentences, step: 3, userId: sessionId || `anon-${Date.now()}` },
        { headers: { 'Content-Type': 'application/json' } }
      );
      
      console.log('‚úÖ DOST analysis yanƒ±tƒ± alƒ±ndƒ±:', data);
      
      const text = data.answer || data.message || data.text || data.response || '';
      setAnalysisText(text);
      setResumeUrl(data.resumeUrl || '');
      
      const audioBase64: string | undefined = data?.audioBase64;
      if (audioBase64 && audioBase64.length > 100) {
        try {
          await playAudioFromBase64(audioBase64);
          setPhase('student');
        } catch {
          // If audio fails, just set phase to student (no text-to-speech)
          setPhase('student');
        }
      } else {
        // No audio available, just set phase to student (no text-to-speech)
        setPhase('student');
      }
    } catch (e) {
      console.error('‚ùå DOST analysis hatasƒ±:', e);
      const fallback = 'Metnin ilk c√ºmlelerinden yola √ßƒ±karak, karƒ±ncalarƒ±n ya≈üamƒ±, yapƒ±sƒ± ve beslenmesi hakkƒ±nda bilgi verildiƒüini tahmin ediyorum.';
      setAnalysisText(fallback);
      setPhase('student');
    } finally {
      setIsAnalyzing(false);
    }
  };

  const renderParagraph = (p: Paragraph, idx: number) => {
    // Determine phase-specific highlighting (first 3 for DOST, others for STUDENT)
    const shouldHighlight = (phase === 'dost' && idx < 3) || (phase === 'student' && idx >= 3);

    // ƒ∞lk 3 paragraf i√ßin firstSentences kullan, diƒüerleri i√ßin dinamik hesapla
    let targetText: string | null = null;
    if (idx < 3) {
      targetText = firstSentences[idx] || null;
    } else if (phase === 'student') {
      // idx >= 3 i√ßin paragrafƒ±n ilk c√ºmlesini hesapla
      const plainText = paragraphToPlain(p);
      targetText = getFirstSentence(plainText);
    }
    
    if (idx < 5) {
      console.log(`üé® Paragraf ${idx} highlight:`, {
        phase,
        shouldHighlight,
        targetText,
        paragraphText: paragraphToPlain(p).substring(0, 100)
      });
    }
    
    // Paragrafƒ±n d√ºz metnini al
    const fullText = paragraphToPlain(p);
    
    // targetText yoksa veya highlight yapƒ±lmayacaksa, normal render
    if (!shouldHighlight || !targetText) {
      const parts: React.ReactElement[] = [];
      p.forEach((seg, i) => {
        const base = seg.bold ? 'font-bold' : undefined;
        parts.push(<span key={i} className={base}>{seg.text}</span>);
      });
      return <p key={idx} className="mt-3 leading-relaxed text-gray-800">{parts}</p>;
    }
    
    // targetText'in paragraftaki konumunu bul
    const targetStart = fullText.indexOf(targetText);
    const targetEnd = targetStart + targetText.length;
    
    if (targetStart < 0) {
      // targetText bulunamadƒ±, normal render
      const parts: React.ReactElement[] = [];
      p.forEach((seg, i) => {
        const base = seg.bold ? 'font-bold' : undefined;
        parts.push(<span key={i} className={base}>{seg.text}</span>);
      });
      return <p key={idx} className="mt-3 leading-relaxed text-gray-800">{parts}</p>;
    }
    
    // Her segment i√ßin karakter pozisyonunu takip ederek highlight yap
    const parts: React.ReactElement[] = [];
    let charPos = 0;
    let keyCounter = 0;
    
    p.forEach((seg) => {
      const segStart = charPos;
      const segEnd = charPos + seg.text.length;
      const base = seg.bold ? 'font-bold' : '';
      
      // Bu segment targetText ile kesi≈üiyor mu?
      if (segEnd <= targetStart || segStart >= targetEnd) {
        // Kesi≈ümiyor - normal render
        parts.push(<span key={keyCounter++} className={base || undefined}>{seg.text}</span>);
      } else {
        // Kesi≈üiyor - b√∂l√ºmlere ayƒ±r
        
        // Segment ba≈üƒ± targetText'ten √∂nce mi?
        if (segStart < targetStart) {
          const beforeText = seg.text.substring(0, targetStart - segStart);
          parts.push(<span key={keyCounter++} className={base || undefined}>{beforeText}</span>);
        }
        
        // Highlight edilecek kƒ±sƒ±m
        const highlightStart = Math.max(0, targetStart - segStart);
        const highlightEnd = Math.min(seg.text.length, targetEnd - segStart);
        const highlightText = seg.text.substring(highlightStart, highlightEnd);
        parts.push(
          <span key={keyCounter++} className={`rounded px-1 bg-yellow-300 ${base}`}>{highlightText}</span>
        );
        
        // Segment sonu targetText'ten sonra mƒ±?
        if (segEnd > targetEnd) {
          const afterText = seg.text.substring(targetEnd - segStart);
          parts.push(<span key={keyCounter++} className={base || undefined}>{afterText}</span>);
        }
      }
      
      charPos = segEnd;
    });
    
    return <p key={idx} className="mt-3 leading-relaxed text-gray-800">{parts}</p>;
  };

  const handleVoiceSubmit = async (audioBlob: Blob) => {
    if (!story) return;
    setIsProcessingVoice(true);
    console.log('üé§ √áocuk sesi g√∂nderiliyor (submitChildrenVoice API)...');
    
    // Calculate student phase target sentences (paragraphs 3+)
    const studentSentences = paragraphs.slice(3).map(p => 
      getFirstSentence(paragraphToPlain(p))
    ).filter(Boolean);
    
    console.log('üìù Student phase hedef c√ºmleler:', studentSentences);
    
    try {
      // Use sessionId for consistency with DOST API
      const response: Level1ChildrenVoiceResponse = await submitChildrenVoice(
        audioBlob,
        resumeUrl,
        story.title,
        3,
        'cumle_tahmini',
        sessionId || `anon-${Date.now()}`, // sessionId (same as userId in DOST API)
        studentSentences // Target sentences for n8n comparison
      );

      console.log('‚úÖ √áocuk sesi yanƒ±tƒ± alƒ±ndƒ±:', response);
      
      const responseText = response.respodKidVoice || response.message || response.text || response.response || 'Te≈üekk√ºrler! Tahminlerini dinledim.';
      setChildrenVoiceResponse(responseText);
      
      // Play response audio if available
      if (response.audioBase64 && response.audioBase64.length > 100) {
        try {
          await playAudioFromBase64(response.audioBase64);
        } catch {
          // Audio playback failed, continue silently
        }
      }
    } catch (e) {
      console.error('‚ùå √áocuk sesi g√∂nderim hatasƒ±:', e);
      const fallback = '√áok iyi! Tahminlerin mantƒ±klƒ± g√∂r√ºn√ºyor.';
      setChildrenVoiceResponse(fallback);
    } finally {
      setIsProcessingVoice(false);
    }
  };

  if (!story) {
    return <div className="w-full max-w-5xl mx-auto px-4">Y√ºkleniyor...</div>;
  }

  return (
    <div className="w-full max-w-5xl mx-auto px-4">
      <audio ref={audioRef} preload="auto" />
      <h2 className="text-2xl font-bold text-purple-800 mb-4">3. Adƒ±m: Anlama √áalƒ±≈ümasƒ±</h2>

      <div className="mb-4">
        <img src={getStoryImageUrl(story.image)} alt={story.title} className="w-full max-w-xs mx-auto rounded-xl shadow" />
      </div>

      <div className="bg-white rounded-xl shadow p-6">
        {isAnalyzing && phase === 'dost' && (
          <div className="mb-4 p-3 bg-blue-50 border border-blue-200 rounded">DOST metnin ilk c√ºmlelerini okuyor ve tahmin ediyor...</div>
        )}
        <div className="text-lg">
          {paragraphs.map((p, idx) => renderParagraph(p, idx))}
        </div>

        {phase === 'student' && !childrenVoiceResponse && (
          <div className="mt-6 text-center">
            <p className="mb-4 text-xl font-bold text-green-700">Hadi sƒ±ra sende! Mikrofona konu≈ü</p>
            <VoiceRecorder 
              onSave={handleVoiceSubmit} 
              onPlayStart={() => { try { window.dispatchEvent(new Event('STOP_ALL_AUDIO' as any)); } catch {} }} 
              storyId={storyId}
              level={1}
              step={3}
            />
            {isProcessingVoice && (
              <p className="mt-2 text-blue-600 font-medium">DOST senin s√∂zlerini deƒüerlendiriyor...</p>
            )}
          </div>
        )}

        {childrenVoiceResponse && (
          <div className="mt-6 p-4 bg-green-50 rounded border border-green-200">
            <h3 className="font-bold text-green-800 mb-2">üó£Ô∏è DOST'un Yorumu:</h3>
            <p className="text-green-700 text-lg">{childrenVoiceResponse}</p>
          </div>
        )}
      </div>
    </div>
  );
}
